{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio\n",
        "!pip install modlamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LmkTLh65y__",
        "outputId": "d64300ee-91b3-43a5-9567-6dffe3eddb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Bio in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.84)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.26.4)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->Bio) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (4.3.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n",
            "Requirement already satisfied: modlamp in /usr/local/lib/python3.10/dist-packages (4.3.0)\n",
            "Requirement already satisfied: setuptools>=20.2.2 in /usr/local/lib/python3.10/dist-packages (from modlamp) (75.1.0)\n",
            "Requirement already satisfied: nose>=1.3.7 in /usr/local/lib/python3.10/dist-packages (from modlamp) (1.3.7)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from modlamp) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from modlamp) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from modlamp) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from modlamp) (1.5.2)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from modlamp) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from modlamp) (2.32.3)\n",
            "Requirement already satisfied: lxml>=3.6.4 in /usr/local/lib/python3.10/dist-packages (from modlamp) (5.3.0)\n",
            "Requirement already satisfied: joblib>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from modlamp) (1.4.2)\n",
            "Requirement already satisfied: mysql-connector-python==8.0.17 in /usr/local/lib/python3.10/dist-packages (from modlamp) (8.0.17)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mysql-connector-python==8.0.17->modlamp) (4.25.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->modlamp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->modlamp) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->modlamp) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.11.1->modlamp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.11.1->modlamp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.11.1->modlamp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.11.1->modlamp) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->modlamp) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.1->modlamp) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Bio import Seq, SeqIO\n",
        "\n",
        "\n",
        "def write_fasta(df, file_path, abbr_columns=None):\n",
        "    \"\"\"\n",
        "    Save dataframe to a .fasta file, the df should contain at least columns named \"Id\" and \"Sequence\"\n",
        "\n",
        "    df: dataframe for saving .fasta\n",
        "    file_path: path(string) for saving the fasta file\n",
        "    abbr_columns: string columns for adding abbreviations. Multiple abbr are splited by '|'.\n",
        "    \"\"\"\n",
        "    Seqrecords = [SeqIO.SeqRecord(id=row['Id'],\n",
        "                              seq=Seq.Seq(row['Sequence']),\n",
        "                              description='|'.join(row[abbr_columns] if abbr_columns is not None else \"\")) \\\n",
        "             for idn, row in df.iterrows()]\n",
        "    with open(file_path, 'w+') as fhandle:\n",
        "        SeqIO.write(Seqrecords, fhandle, \"fasta-2line\")\n",
        "        print(\"Saved {:d} sequences.\".format(len(Seqrecords)))\n",
        "\n",
        "\n",
        "def read_fasta(fname):\n",
        "    '''\n",
        "    Read fasta file to dictionary\n",
        "    Input: path name of fasta\n",
        "    Output: dataframe of Peptide Seq {ID1: Seq1, ID2: Seq2,...}\n",
        "    '''\n",
        "    with open(fname, \"rU\") as f:\n",
        "        seq_dict = [(record.id, record.seq._data) for record in SeqIO.parse(f, \"fasta\")]\n",
        "    seq_df = pd.DataFrame(data=seq_dict, columns=[\"Id\", \"Sequence\"])\n",
        "    seq_df[\"Sequence\"]=seq_df[\"Sequence\"].apply(lambda x:x.decode(\"utf-8\"))\n",
        "    return seq_df"
      ],
      "metadata": {
        "id": "AkTE9pLj6QsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3H7MXCi3Wye",
        "outputId": "96d02df7-bda1-42aa-e29d-4cd8b932a94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:481: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:483: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:485: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:481: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:483: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:485: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-4-834e67b25f05>:481: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if n is 1:\n",
            "<ipython-input-4-834e67b25f05>:483: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif n is 2:\n",
            "<ipython-input-4-834e67b25f05>:485: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif n is 3:\n"
          ]
        }
      ],
      "source": [
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis as PA\n",
        "from modlamp.descriptors import PeptideDescriptor, GlobalDescriptor\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from utils import read_fasta\n",
        "import pandas as pd\n",
        "import os, re, math, platform\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Miscellaneous\n",
        "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
        "             'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
        "             'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "n_gram statistics\n",
        "\"\"\"\n",
        "\n",
        "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
        "            'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
        "            'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "\n",
        "\n",
        "def get_aan_corpus(n=2):\n",
        "    '''\n",
        "    Get AA corpus of n_gram (e.g. Di, Tri, etc.)\n",
        "    Output: AA n_gram corpus ((e.g. Di:400, Tri:3000, etc.))\n",
        "    '''\n",
        "    n_corpus = []\n",
        "    if n <= 2:\n",
        "        for i in _AALetter:\n",
        "            for j in _AALetter:\n",
        "               n_corpus.append(\"{}{}\".format(i, j))\n",
        "        return n_corpus\n",
        "    for i in get_aan_corpus(n - 1):\n",
        "        for j in _AALetter:\n",
        "            n_corpus.append(\"{}{}\".format(i, j))\n",
        "    return n_corpus\n",
        "\n",
        "\n",
        "def get_ngram_counts(seq, n=2):\n",
        "    '''\n",
        "    Get n_gram statistics\n",
        "    Input: peptide sequence and n\n",
        "    Ouput: n_gram statistic (dictionary) {A.A Corp: Counts}\n",
        "    '''\n",
        "    # Get the name of ngram feature\n",
        "    if n == 2:\n",
        "        prefix = 'DPC'\n",
        "    elif n == 3:\n",
        "        prefix = 'TPC'\n",
        "    else:\n",
        "        prefix = '{}gram'.format(n)\n",
        "\n",
        "    ngrams = [seq[i: i + n] for i in range(len(seq) - n + 1)]\n",
        "    n_corpus = get_aan_corpus(n)\n",
        "    ngram_stat = {}\n",
        "    for aa_ng in n_corpus:\n",
        "        ngram_stat['{}|{}'.format(prefix, aa_ng)] = ngrams.count(aa_ng) / len(ngrams) * 100\n",
        "    return ngram_stat\n",
        "\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "\n",
        "def minSequenceLengthWithNormalAA(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(re.sub('-', '', i[1])):\n",
        "            minLen = len(re.sub('-', '', i[1]))\n",
        "    return minLen\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    input.fasta:      the input protein sequence file in fasta format.\n",
        "    k_space:          the gap of two amino acids, integer, defaule: 5\n",
        "    output:           the encoding file, default: 'encodings.tsv'\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generateGroupPairs(groupKey):\n",
        "    gPair = {}\n",
        "    for key1 in groupKey:\n",
        "        for key2 in groupKey:\n",
        "            gPair['CKSAAGP|'+key1+'.'+key2] = 0\n",
        "    return gPair\n",
        "\n",
        "\n",
        "def cksaagp(fastas, gap = 5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be greater than the (gap value) + 2 = ' + str(gap+2) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    group = {'aliphatic': 'GAVLMI',\n",
        "             'aromatic': 'FYW',\n",
        "             'postivecharge': 'KRH',\n",
        "             'negativecharge': 'DE',\n",
        "             'uncharge': 'STCPNQ'}\n",
        "\n",
        "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
        "\n",
        "    groupKey = group.keys()\n",
        "\n",
        "    index = {}\n",
        "    for key in groupKey:\n",
        "        for aa in group[key]:\n",
        "            index[aa] = key\n",
        "\n",
        "    gPairIndex = []\n",
        "    for key1 in groupKey:\n",
        "        for key2 in groupKey:\n",
        "            gPairIndex.append('CKSAAGP|'+key1+'.'+key2)\n",
        "\n",
        "    encodings = []\n",
        "    header = ['#']\n",
        "    for g in range(gap + 1):\n",
        "        for p in gPairIndex:\n",
        "            header.append(p+'.gap'+str(g))\n",
        "    encodings.append(header)\n",
        "\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], re.sub('-', '', i[1])\n",
        "        code = [name]\n",
        "        for g in range(gap + 1):\n",
        "            gPair = generateGroupPairs(groupKey)\n",
        "            sum = 0\n",
        "            for p1 in range(len(sequence)):\n",
        "                p2 = p1 + g + 1\n",
        "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
        "                    gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] = gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] + 1\n",
        "                    sum = sum + 1\n",
        "\n",
        "            if sum == 0:\n",
        "                for gp in gPairIndex:\n",
        "                    code.append(0)\n",
        "            else:\n",
        "                for gp in gPairIndex:\n",
        "                    code.append(gPair[gp] / sum)\n",
        "\n",
        "        encodings.append(code)\n",
        "\n",
        "    return encodings\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    input.fasta:      the input protein sequence file in fasta format.\n",
        "    lambda:           the lambda value, integer, defaule: 30\n",
        "    output:           the encoding file, default: 'encodings.tsv'\n",
        "\"\"\"\n",
        "\n",
        "def Rvalue(aa1, aa2, AADict, Matrix):\n",
        "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n",
        "\n",
        "\n",
        "def paac(fastas, lambdaValue=30, w=0.05, **kw):\n",
        "    if minSequenceLengthWithNormalAA(fastas) < lambdaValue + 1:\n",
        "        print('Error: all the sequence length should be larger than the lambdaValue+1: ' + str(lambdaValue + 1) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    dataFile = 'PAAC.txt'\n",
        "    with open(dataFile) as f:\n",
        "        records = f.readlines()\n",
        "    AA = ''.join(records[0].rstrip().split()[1:])\n",
        "    AADict = {}\n",
        "    for i in range(len(AA)):\n",
        "        AADict[AA[i]] = i\n",
        "    AAProperty = []\n",
        "    AAPropertyNames = []\n",
        "    for i in range(1, len(records)):\n",
        "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
        "        AAProperty.append([float(j) for j in array[1:]])\n",
        "        AAPropertyNames.append(array[0])\n",
        "\n",
        "    AAProperty1 = []\n",
        "    for i in AAProperty:\n",
        "        meanI = sum(i) / 20\n",
        "        fenmu = math.sqrt(sum([(j-meanI)**2 for j in i])/20)\n",
        "        AAProperty1.append([(j-meanI)/fenmu for j in i])\n",
        "\n",
        "    encodings = []\n",
        "    header = ['#']\n",
        "    for aa in AA:\n",
        "        header.append('PAAC|' + aa)\n",
        "    for n in range(1, lambdaValue + 1):\n",
        "        header.append('PAAC|lambda' + str(n))\n",
        "    encodings.append(header)\n",
        "\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], re.sub('-', '', i[1])\n",
        "        code = [name]\n",
        "        theta = []\n",
        "        for n in range(1, lambdaValue + 1):\n",
        "            theta.append(\n",
        "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (\n",
        "                len(sequence) - n))\n",
        "        myDict = {}\n",
        "        for aa in AA:\n",
        "            myDict[aa] = sequence.count(aa)\n",
        "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
        "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
        "        encodings.append(code)\n",
        "    return encodings\n",
        "\n",
        "\n",
        "def GAAC(fastas, **kw):\n",
        "\tgroup = {\n",
        "\t\t'alphatic': 'GAVLMI',\n",
        "\t\t'aromatic': 'FYW',\n",
        "\t\t'postivecharge': 'KRH',\n",
        "\t\t'negativecharge': 'DE',\n",
        "\t\t'uncharge': 'STCPNQ'\n",
        "\t}\n",
        "\n",
        "\tgroupKey = group.keys()\n",
        "\n",
        "\tencodings = []\n",
        "\theader = ['#']\n",
        "\tfor key in groupKey:\n",
        "\t\theader.append(\"GAAC|\"+key)\n",
        "\tencodings.append(header)\n",
        "\n",
        "\tfor i in fastas:\n",
        "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
        "\t\tcode = [name]\n",
        "\t\tcount = Counter(sequence)\n",
        "\t\tmyDict = {}\n",
        "\t\tfor key in groupKey:\n",
        "\t\t\tfor aa in group[key]:\n",
        "\t\t\t\tmyDict[key] = myDict.get(key, 0) + count[aa]\n",
        "\n",
        "\t\tfor key in groupKey:\n",
        "\t\t\tcode.append(myDict[key]/len(sequence))\n",
        "\t\tencodings.append(code)\n",
        "\n",
        "\treturn encodings\n",
        "\n",
        "\n",
        "def GDPC(fastas, **kw):\n",
        "\tgroup = {\n",
        "\t\t'alphaticr': 'GAVLMI',\n",
        "\t\t'aromatic': 'FYW',\n",
        "\t\t'postivecharger': 'KRH',\n",
        "\t\t'negativecharger': 'DE',\n",
        "\t\t'uncharger': 'STCPNQ'\n",
        "\t}\n",
        "\n",
        "\tgroupKey = group.keys()\n",
        "\tbaseNum = len(groupKey)\n",
        "\tdipeptide = [g1+'.'+g2 for g1 in groupKey for g2 in groupKey]\n",
        "\n",
        "\tindex = {}\n",
        "\tfor key in groupKey:\n",
        "\t\tfor aa in group[key]:\n",
        "\t\t\tindex[aa] = key\n",
        "\n",
        "\tencodings = []\n",
        "\theader = ['#'] + ['GDPC|'+dipname for dipname in dipeptide]\n",
        "\tencodings.append(header)\n",
        "\n",
        "\tfor i in fastas:\n",
        "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
        "\n",
        "\t\tcode = [name]\n",
        "\t\tmyDict = {}\n",
        "\t\tfor t in dipeptide:\n",
        "\t\t\tmyDict[t] = 0\n",
        "\n",
        "\t\tsum = 0\n",
        "\t\tfor j in range(len(sequence) - 2 + 1):\n",
        "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]] + 1\n",
        "\t\t\tsum = sum +1\n",
        "\n",
        "\t\tif sum == 0:\n",
        "\t\t\tfor t in dipeptide:\n",
        "\t\t\t\tcode.append(0)\n",
        "\t\telse:\n",
        "\t\t\tfor t in dipeptide:\n",
        "\t\t\t\tcode.append(myDict[t]/sum)\n",
        "\t\tencodings.append(code)\n",
        "\n",
        "\treturn encodings\n",
        "\n",
        "\n",
        "def GTPC(fastas, **kw):\n",
        "\tgroup = {\n",
        "\t\t'alphaticr': 'GAVLMI',\n",
        "\t\t'aromatic': 'FYW',\n",
        "\t\t'postivecharger': 'KRH',\n",
        "\t\t'negativecharger': 'DE',\n",
        "\t\t'uncharger': 'STCPNQ'\n",
        "\t}\n",
        "\n",
        "\tgroupKey = group.keys()\n",
        "\tbaseNum = len(groupKey)\n",
        "\ttriple = [g1+'.'+g2+'.'+g3 for g1 in groupKey for g2 in groupKey for g3 in groupKey]\n",
        "\n",
        "\tindex = {}\n",
        "\tfor key in groupKey:\n",
        "\t\tfor aa in group[key]:\n",
        "\t\t\tindex[aa] = key\n",
        "\n",
        "\tencodings = []\n",
        "\theader = ['#'] + ['GTPC|'+tname for tname in triple]\n",
        "\tencodings.append(header)\n",
        "\n",
        "\tfor i in fastas:\n",
        "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
        "\n",
        "\t\tcode = [name]\n",
        "\t\tmyDict = {}\n",
        "\t\tfor t in triple:\n",
        "\t\t\tmyDict[t] = 0\n",
        "\n",
        "\t\tsum = 0\n",
        "\t\tfor j in range(len(sequence) - 3 + 1):\n",
        "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] + 1\n",
        "\t\t\tsum = sum +1\n",
        "\n",
        "\t\tif sum == 0:\n",
        "\t\t\tfor t in triple:\n",
        "\t\t\t\tcode.append(0)\n",
        "\t\telse:\n",
        "\t\t\tfor t in triple:\n",
        "\t\t\t\tcode.append(myDict[t]/sum)\n",
        "\t\tencodings.append(code)\n",
        "\n",
        "\treturn encodings\n",
        "\n",
        "'''\n",
        "Insert Iso_electric Point and net_charge(neutral) feature to the sequence data_frame\n",
        "Input: sequence data_frame {IDx: Seq_x, ...}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., iep, net_charge}\n",
        "'''\n",
        "\n",
        "\n",
        "def insert_phycs(seq_df):\n",
        "    seq_df = seq_df.copy()\n",
        "    #  Function for compute Isoelectric Point or net_charge of peptide\n",
        "    def get_ieq_nc(seq, is_iep=True):\n",
        "        protparam = PA(seq)\n",
        "        return protparam.isoelectric_point() if is_iep else protparam.charge_at_pH(7.0)\n",
        "\n",
        "    # Calculating IsoElectricPoints and NeutralCharge\n",
        "    data_size = seq_df.size\n",
        "    seq_df['PHYC|IEP'] = list(map(get_ieq_nc, seq_df['Sequence'], [True] * data_size))  # IsoElectricPoints\n",
        "    seq_df['PHYC|Net Charge'] = list(map(get_ieq_nc, seq_df['Sequence'], [False] * data_size))  # Charge(Neutral)\n",
        "\n",
        "    # Calculating hydrophobic moment (My assume all peptides are alpha-helix)\n",
        "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'eisenberg')\n",
        "    descrpt.calculate_moment(window=1000, angle=100, modality='max')\n",
        "    seq_df['PHYC|Hydrophobic Moment'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating \"Hopp-Woods\" hydrophobicity\n",
        "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'hopp-woods')\n",
        "    descrpt.calculate_global()\n",
        "    seq_df['PHYC|Hydrophobicity'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating Energy of Transmembrane Propensity\n",
        "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'tm_tend')\n",
        "    descrpt.calculate_global()\n",
        "    seq_df['PHYC|Transmembrane Propensity'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating Aromaticity\n",
        "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
        "    descrpt.aromaticity()\n",
        "    seq_df['PHYC|Aromacity'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating Levitt_alpha_helical Propensity\n",
        "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'levitt_alpha')\n",
        "    descrpt.calculate_global()\n",
        "    seq_df['PHYC|Alpha Helical Propensity'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating Aliphatic Index\n",
        "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
        "    descrpt.aliphatic_index()\n",
        "    seq_df['PHYC|Aliphatic Index'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    # Calculating Boman Index\n",
        "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
        "    descrpt.boman_index()\n",
        "    seq_df['PHYC|Boman Index'] = descrpt.descriptor.reshape(-1)\n",
        "\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "'''\n",
        "Insert Amino acid composition to the sequence data_frame\n",
        "Input: sequence data_frame {IDx: Seq_x}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., AAC_Ax ... AAC_Yx}\n",
        "'''\n",
        "\n",
        "\n",
        "def insert_aac(seq_df):\n",
        "    seq_df = seq_df.copy()\n",
        "    # Compute AAC for peptide in specific A.A\n",
        "    def get_aac(seq, aa):\n",
        "        # print(seq)\n",
        "        return seq.count(aa) / len(seq) * 100\n",
        "\n",
        "    # processing data_frame\n",
        "    data_size = seq_df.size\n",
        "    for ll in _AALetter:\n",
        "        seq_df['AAC|{}'.format(ll)] = list(map(get_aac, seq_df['Sequence'], [ll] * data_size))\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "'''\n",
        "Insert n_grams Descriptor to the sequence data_frame\n",
        "Input: sequence data_frame {IDx: Seq_x, ...}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., ngram_(1), .., ngram(20 ** n)}\n",
        "'''\n",
        "\n",
        "\n",
        "def insert_ngrams(seq_df, n=2):\n",
        "    seq_df = seq_df.copy()\n",
        "    data_size = seq_df.size\n",
        "\n",
        "    ngrams_df = list(map(get_ngram_counts, seq_df['Sequence'], [n] * data_size))\n",
        "    ngrams_df = pd.DataFrame(ngrams_df)  # Convert ngrams features to pd.DataFrame\n",
        "    seq_df = pd.concat([seq_df, ngrams_df], axis=1)\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Insert CKSAAGP Descriptor to the sequence data_frame\n",
        "(Composition of k-spaced amino acid pairs)\n",
        "Input: sequence data_frame {IDx: Seq_x, ...}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def insert_cksaagp(seq_df, gap=2):\n",
        "    seq_df.copy()\n",
        "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
        "    encoding = cksaagp(fastas, gap=gap)\n",
        "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
        "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Insert PAAC Descriptor to the sequence data_frame\n",
        "(Pseudo Amino Acid Composition)\n",
        "Input: sequence data_frame {IDx: Seq_x, ...}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def insert_paac(seq_df, lamb=3, w=0.1):\n",
        "    seq_df = seq_df.copy()\n",
        "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
        "    encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
        "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
        "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Insert Grouped n-gram Descriptor to the sequence data_frame\n",
        "(Pseudo Amino Acid Composition)\n",
        "Input: sequence data_frame {IDx: Seq_x, ...}\n",
        "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def insert_gngram(seq_df, n=1):\n",
        "    seq_df = seq_df.copy()\n",
        "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
        "    # encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
        "    if n is 1:\n",
        "        encoding = GAAC(fastas)\n",
        "    elif n is 2:\n",
        "        encoding = GDPC(fastas)\n",
        "    elif n is 3:\n",
        "        encoding = GTPC(fastas)\n",
        "    else:\n",
        "        raise Warning(\"Invalid n-grams, no features added\")\n",
        "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
        "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
        "    return seq_df\n",
        "\n",
        "\n",
        "def construct_features(seq_df, paaclamb=4, paacw=0.5):\n",
        "    \"\"\"\n",
        "    Construct Features for the AVPIden. We first investigated physiochemical feautres, AAC features, DiC features,\n",
        "    CKSAAGP features, PAAC features, and PHYC features.\n",
        "    Parameters are pre-set accroding to the sequence identities.\n",
        "    \"\"\"\n",
        "    seq_df = insert_aac(seq_df)\n",
        "    seq_df = insert_ngrams(seq_df, n=2)\n",
        "    seq_df = insert_cksaagp(seq_df, gap=3) # As the maximum motif length = 5.\n",
        "    seq_df = insert_paac(seq_df, lamb=paaclamb, w=paacw)\n",
        "    seq_df = insert_phycs(seq_df)\n",
        "\n",
        "    return seq_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cX6tAZbo5yBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Entire\n",
        "    print(\"Translate the entire-stage prediction data...\", flush=True)\n",
        "    # if not os.path.exists(entire_datadir):\n",
        "    #     os.makedirs(entire_datadir)\n",
        "    df = read_fasta(\"filtered_sequences.fasta\")\n",
        "    df = construct_features(df)\n",
        "    print(\"Done!\", flush=True)\n",
        "    print(df)\n",
        "    # # ByFamily\n",
        "    # print(\"Translate the By-Family prediction data...\", flush=True)\n",
        "    # family_datadir = \"data/ByFamily/set\"\n",
        "    # if not os.path.exists(family_datadir):\n",
        "    #     os.makedirs(family_datadir)\n",
        "    # families = [\"Coronaviridae\", \"Flaviviridae\", \"Herpesviridae\",\n",
        "    # \"Orthomyxoviridae\", \"Paramyxoviridae\", \"Retroviridae\"]\n",
        "    # families = families + list(map(lambda x: \"non-\"+x, families))\n",
        "    # for fm in tqdm(families):\n",
        "    #     df = read_fasta(\"./Fasta/ByFamily/fasta/{:s}.faa\".format(fm))\n",
        "    #     df = construct_features(df)\n",
        "    #     df.to_csv(os.path.join(family_datadir, \"{:s}.csv\".format(fm)), index=False)\n",
        "    # print(\"Done!\", flush=True)\n",
        "    # # By virus\n",
        "    # print(\"Translate the By-Virus prediction data...\", flush=True)\n",
        "    # virus_datadir = \"data/ByVirus/set\"\n",
        "    # if not os.path.exists(virus_datadir):\n",
        "    #     os.makedirs(virus_datadir)\n",
        "    # viruses = [\"FIV\", \"HCV\", \"HIV\", \"HPIV3\", \"HSV1\", \"INFVA\",  \"RSV\", \"SARSCoV\"]\n",
        "    # viruses = viruses + list(map(lambda x: \"non-\"+x, viruses))\n",
        "    # for vm in tqdm(viruses):\n",
        "    #     df = read_fasta(\"./Fasta/ByVirus/fasta/{:s}.faa\".format(vm))\n",
        "    #     df = construct_features(df)\n",
        "    #     df.to_csv(os.path.join(virus_datadir, \"{:s}.csv\".format(vm)), index=False)\n",
        "    # print(\"Done!\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "nWfdwzyZ3f_o",
        "outputId": "05eddc73-04a3-46f4-d7b5-21a19ce30d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the entire-stage prediction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-621c5b3551c4>:28: DeprecationWarning: 'U' mode is deprecated\n",
            "  with open(fname, \"rU\") as f:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-06a237266853>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#     os.makedirs(entire_datadir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_fasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filtered_sequences.fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-834e67b25f05>\u001b[0m in \u001b[0;36mconstruct_features\u001b[0;34m(seq_df, paaclamb, paacw)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0mParameters\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mset\u001b[0m \u001b[0maccroding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msequence\u001b[0m \u001b[0midentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \"\"\"\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mseq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_aac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0mseq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mseq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_cksaagp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# As the maximum motif length = 5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-834e67b25f05>\u001b[0m in \u001b[0;36minsert_aac\u001b[0;34m(seq_df)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mll\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_AALetter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mseq_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AAC|{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_aac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-834e67b25f05>\u001b[0m in \u001b[0;36mget_aac\u001b[0;34m(seq, aa)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mseq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# Compute AAC for peptide in specific A.A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_aac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;31m# print(seq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 逐行读取FASTA文件，生成数据\n",
        "def read_fasta_in_chunks(fasta_file, chunk_size=10000):\n",
        "    sequences = []\n",
        "    with open(fasta_file, 'r') as file:\n",
        "        sequence_id = None\n",
        "        sequence = []\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\">\"):\n",
        "                if sequence_id is not None:\n",
        "                    sequences.append({\"Id\": sequence_id, \"Sequence\": ''.join(sequence)})\n",
        "                sequence_id = line[1:]  # 去掉 \">\" 符号\n",
        "                sequence = []\n",
        "            else:\n",
        "                sequence.append(line)\n",
        "            # 每处理 chunk_size 行数据，yield 一次\n",
        "            if len(sequences) >= chunk_size:\n",
        "                yield pd.DataFrame(sequences)\n",
        "                sequences = []\n",
        "        # 处理最后一批\n",
        "        if sequence_id is not None:\n",
        "            sequences.append({\"Id\": sequence_id, \"Sequence\": ''.join(sequence)})\n",
        "        if sequences:\n",
        "            # 打印最后一批的大小以确认没有问题\n",
        "            print(f\"Processing last chunk with {len(sequences)} sequences.\")\n",
        "            yield pd.DataFrame(sequences)\n",
        "\n",
        "\n",
        "# 假设 construct_features(df) 是定义好的特征构建函数\n",
        "def process_and_save_in_chunks(input_fasta, output_csv, chunk_size=10000):\n",
        "    processed_chunks = []\n",
        "    for chunk in read_fasta_in_chunks(input_fasta, chunk_size):\n",
        "        processed_chunk = construct_features(chunk)  # 调用特征构建函数\n",
        "        processed_chunks.append(processed_chunk)\n",
        "        # 可选：将每个chunk保存到文件（防止中途出错丢失结果）\n",
        "        processed_chunk.to_csv(output_csv, mode='a', index=False, header=not os.path.exists(output_csv))\n",
        "    return processed_chunks\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Translate the entire-stage prediction data in chunks...\", flush=True)\n",
        "\n",
        "    input_fasta = \"filtered_sequences.fasta\"\n",
        "    output_csv = \"processed_features.csv\"\n",
        "\n",
        "    # 确保之前的输出文件不存在\n",
        "    if os.path.exists(output_csv):\n",
        "        os.remove(output_csv)\n",
        "\n",
        "    # 分批处理数据并保存到CSV\n",
        "    process_and_save_in_chunks(input_fasta, output_csv, chunk_size=10000)\n",
        "\n",
        "    print(\"Done!\", flush=True)\n",
        "    print(f\"Processed data saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuD9zQdQ0N5i",
        "outputId": "e9615640-f2e9-4a33-b3e7-470e1ea95131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the entire-stage prediction data in chunks...\n",
            "Processing last chunk with 6769 sequences.\n",
            "Done!\n",
            "Processed data saved to processed_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('train_feature.csv',index=False)"
      ],
      "metadata": {
        "id": "rDKRbqs9Drrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1QnlAb2ncsJq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkvNO7MqQg2b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}