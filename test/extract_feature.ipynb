{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LmkTLh65y__",
    "outputId": "d64300ee-91b3-43a5-9567-6dffe3eddb55"
   },
   "outputs": [],
   "source": [
    "# !pip install Bio\n",
    "# !pip install modlamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AkTE9pLj6QsZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import Seq, SeqIO\n",
    "\n",
    "\n",
    "def write_fasta(df, file_path, abbr_columns=None):\n",
    "    \"\"\"\n",
    "    Save dataframe to a .fasta file, the df should contain at least columns named \"Id\" and \"Sequence\"\n",
    "\n",
    "    df: dataframe for saving .fasta\n",
    "    file_path: path(string) for saving the fasta file\n",
    "    abbr_columns: string columns for adding abbreviations. Multiple abbr are splited by '|'.\n",
    "    \"\"\"\n",
    "    Seqrecords = [SeqIO.SeqRecord(id=row['Id'],\n",
    "                              seq=Seq.Seq(row['Sequence']),\n",
    "                              description='|'.join(row[abbr_columns] if abbr_columns is not None else \"\")) \\\n",
    "             for idn, row in df.iterrows()]\n",
    "    with open(file_path, 'w+') as fhandle:\n",
    "        SeqIO.write(Seqrecords, fhandle, \"fasta-2line\")\n",
    "        print(\"Saved {:d} sequences.\".format(len(Seqrecords)))\n",
    "\n",
    "\n",
    "def read_fasta(fname):\n",
    "    '''\n",
    "    Read fasta file to dictionary\n",
    "    Input: path name of fasta\n",
    "    Output: dataframe of Peptide Seq {ID1: Seq1, ID2: Seq2,...}\n",
    "    '''\n",
    "    with open(fname, \"rU\") as f:\n",
    "        seq_dict = [(record.id, record.seq._data) for record in SeqIO.parse(f, \"fasta\")]\n",
    "    seq_df = pd.DataFrame(data=seq_dict, columns=[\"Id\", \"Sequence\"])\n",
    "    seq_df[\"Sequence\"]=seq_df[\"Sequence\"].apply(lambda x:x.decode(\"utf-8\"))\n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3H7MXCi3Wye",
    "outputId": "96d02df7-bda1-42aa-e29d-4cd8b932a94b"
   },
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis as PA\n",
    "from modlamp.descriptors import PeptideDescriptor, GlobalDescriptor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from utils import read_fasta\n",
    "import pandas as pd\n",
    "import os, re, math, platform\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Miscellaneous\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "             'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
    "             'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "n_gram statistics\n",
    "\"\"\"\n",
    "\n",
    "_AALetter = ['A', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "            'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
    "            'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "\n",
    "def get_aan_corpus(n=2):\n",
    "    '''\n",
    "    Get AA corpus of n_gram (e.g. Di, Tri, etc.)\n",
    "    Output: AA n_gram corpus ((e.g. Di:400, Tri:3000, etc.))\n",
    "    '''\n",
    "    n_corpus = []\n",
    "    if n <= 2:\n",
    "        for i in _AALetter:\n",
    "            for j in _AALetter:\n",
    "               n_corpus.append(\"{}{}\".format(i, j))\n",
    "        return n_corpus\n",
    "    for i in get_aan_corpus(n - 1):\n",
    "        for j in _AALetter:\n",
    "            n_corpus.append(\"{}{}\".format(i, j))\n",
    "    return n_corpus\n",
    "\n",
    "\n",
    "def get_ngram_counts(seq, n=2):\n",
    "    '''\n",
    "    Get n_gram statistics\n",
    "    Input: peptide sequence and n\n",
    "    Ouput: n_gram statistic (dictionary) {A.A Corp: Counts}\n",
    "    '''\n",
    "    # Get the name of ngram feature\n",
    "    if n == 2:\n",
    "        prefix = 'DPC'\n",
    "    elif n == 3:\n",
    "        prefix = 'TPC'\n",
    "    else:\n",
    "        prefix = '{}gram'.format(n)\n",
    "\n",
    "    ngrams = [seq[i: i + n] for i in range(len(seq) - n + 1)]\n",
    "    n_corpus = get_aan_corpus(n)\n",
    "    ngram_stat = {}\n",
    "    for aa_ng in n_corpus:\n",
    "        ngram_stat['{}|{}'.format(prefix, aa_ng)] = ngrams.count(aa_ng) / len(ngrams) * 100\n",
    "    return ngram_stat\n",
    "\n",
    "\n",
    "def minSequenceLength(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(i[1]):\n",
    "            minLen = len(i[1])\n",
    "    return minLen\n",
    "\n",
    "\n",
    "def minSequenceLengthWithNormalAA(fastas):\n",
    "    minLen = 10000\n",
    "    for i in fastas:\n",
    "        if minLen > len(re.sub('-', '', i[1])):\n",
    "            minLen = len(re.sub('-', '', i[1]))\n",
    "    return minLen\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    k_space:          the gap of two amino acids, integer, defaule: 5\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generateGroupPairs(groupKey):\n",
    "    gPair = {}\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPair['CKSAAGP|'+key1+'.'+key2] = 0\n",
    "    return gPair\n",
    "\n",
    "\n",
    "def cksaagp(fastas, gap = 5, **kw):\n",
    "    if gap < 0:\n",
    "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    if minSequenceLength(fastas) < gap+2:\n",
    "        print('Error: all the sequence length should be greater than the (gap value) + 2 = ' + str(gap+2) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    group = {'aliphatic': 'GAVLMI',\n",
    "             'aromatic': 'FYW',\n",
    "             'postivecharge': 'KRH',\n",
    "             'negativecharge': 'DE',\n",
    "             'uncharge': 'STCPNQ'}\n",
    "\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    gPairIndex = []\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPairIndex.append('CKSAAGP|'+key1+'.'+key2)\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for g in range(gap + 1):\n",
    "        for p in gPairIndex:\n",
    "            header.append(p+'.gap'+str(g))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        for g in range(gap + 1):\n",
    "            gPair = generateGroupPairs(groupKey)\n",
    "            sum = 0\n",
    "            for p1 in range(len(sequence)):\n",
    "                p2 = p1 + g + 1\n",
    "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
    "                    gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] = gPair['CKSAAGP|'+index[sequence[p1]]+'.'+index[sequence[p2]]] + 1\n",
    "                    sum = sum + 1\n",
    "\n",
    "            if sum == 0:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(0)\n",
    "            else:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(gPair[gp] / sum)\n",
    "\n",
    "        encodings.append(code)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    input.fasta:      the input protein sequence file in fasta format.\n",
    "    lambda:           the lambda value, integer, defaule: 30\n",
    "    output:           the encoding file, default: 'encodings.tsv'\n",
    "\"\"\"\n",
    "\n",
    "def Rvalue(aa1, aa2, AADict, Matrix):\n",
    "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n",
    "\n",
    "\n",
    "def paac(fastas, lambdaValue=30, w=0.05, **kw):\n",
    "    if minSequenceLengthWithNormalAA(fastas) < lambdaValue + 1:\n",
    "        print('Error: all the sequence length should be larger than the lambdaValue+1: ' + str(lambdaValue + 1) + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    dataFile = 'PAAC.txt'\n",
    "    with open(dataFile) as f:\n",
    "        records = f.readlines()\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records)):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j-meanI)**2 for j in i])/20)\n",
    "        AAProperty1.append([(j-meanI)/fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for aa in AA:\n",
    "        header.append('PAAC|' + aa)\n",
    "    for n in range(1, lambdaValue + 1):\n",
    "        header.append('PAAC|lambda' + str(n))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        theta = []\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            theta.append(\n",
    "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (\n",
    "                len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
    "        encodings.append(code)\n",
    "    return encodings\n",
    "\n",
    "\n",
    "def GAAC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphatic': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharge': 'KRH',\n",
    "\t\t'negativecharge': 'DE',\n",
    "\t\t'uncharge': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#']\n",
    "\tfor key in groupKey:\n",
    "\t\theader.append(\"GAAC|\"+key)\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\t\tcode = [name]\n",
    "\t\tcount = Counter(sequence)\n",
    "\t\tmyDict = {}\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tfor aa in group[key]:\n",
    "\t\t\t\tmyDict[key] = myDict.get(key, 0) + count[aa]\n",
    "\n",
    "\t\tfor key in groupKey:\n",
    "\t\t\tcode.append(myDict[key]/len(sequence))\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GDPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\tdipeptide = [g1+'.'+g2 for g1 in groupKey for g2 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GDPC|'+dipname for dipname in dipeptide]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in dipeptide:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 2 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in dipeptide:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "\n",
    "def GTPC(fastas, **kw):\n",
    "\tgroup = {\n",
    "\t\t'alphaticr': 'GAVLMI',\n",
    "\t\t'aromatic': 'FYW',\n",
    "\t\t'postivecharger': 'KRH',\n",
    "\t\t'negativecharger': 'DE',\n",
    "\t\t'uncharger': 'STCPNQ'\n",
    "\t}\n",
    "\n",
    "\tgroupKey = group.keys()\n",
    "\tbaseNum = len(groupKey)\n",
    "\ttriple = [g1+'.'+g2+'.'+g3 for g1 in groupKey for g2 in groupKey for g3 in groupKey]\n",
    "\n",
    "\tindex = {}\n",
    "\tfor key in groupKey:\n",
    "\t\tfor aa in group[key]:\n",
    "\t\t\tindex[aa] = key\n",
    "\n",
    "\tencodings = []\n",
    "\theader = ['#'] + ['GTPC|'+tname for tname in triple]\n",
    "\tencodings.append(header)\n",
    "\n",
    "\tfor i in fastas:\n",
    "\t\tname, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "\t\tcode = [name]\n",
    "\t\tmyDict = {}\n",
    "\t\tfor t in triple:\n",
    "\t\t\tmyDict[t] = 0\n",
    "\n",
    "\t\tsum = 0\n",
    "\t\tfor j in range(len(sequence) - 3 + 1):\n",
    "\t\t\tmyDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] = myDict[index[sequence[j]]+'.'+index[sequence[j+1]]+'.'+index[sequence[j+2]]] + 1\n",
    "\t\t\tsum = sum +1\n",
    "\n",
    "\t\tif sum == 0:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(0)\n",
    "\t\telse:\n",
    "\t\t\tfor t in triple:\n",
    "\t\t\t\tcode.append(myDict[t]/sum)\n",
    "\t\tencodings.append(code)\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "'''\n",
    "Insert Iso_electric Point and net_charge(neutral) feature to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., iep, net_charge}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_phycs(seq_df):\n",
    "    seq_df = seq_df.copy()\n",
    "    #  Function for compute Isoelectric Point or net_charge of peptide\n",
    "    def get_ieq_nc(seq, is_iep=True):\n",
    "        protparam = PA(seq)\n",
    "        return protparam.isoelectric_point() if is_iep else protparam.charge_at_pH(7.0)\n",
    "\n",
    "    # Calculating IsoElectricPoints and NeutralCharge\n",
    "    data_size = seq_df.size\n",
    "    seq_df['PHYC|IEP'] = list(map(get_ieq_nc, seq_df['Sequence'], [True] * data_size))  # IsoElectricPoints\n",
    "    seq_df['PHYC|Net Charge'] = list(map(get_ieq_nc, seq_df['Sequence'], [False] * data_size))  # Charge(Neutral)\n",
    "\n",
    "    # Calculating hydrophobic moment (My assume all peptides are alpha-helix)\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'eisenberg')\n",
    "    descrpt.calculate_moment(window=1000, angle=100, modality='max')\n",
    "    seq_df['PHYC|Hydrophobic Moment'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating \"Hopp-Woods\" hydrophobicity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'hopp-woods')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Hydrophobicity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Energy of Transmembrane Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'tm_tend')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Transmembrane Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aromaticity\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aromaticity()\n",
    "    seq_df['PHYC|Aromacity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Levitt_alpha_helical Propensity\n",
    "    descrpt = PeptideDescriptor(seq_df['Sequence'].values, 'levitt_alpha')\n",
    "    descrpt.calculate_global()\n",
    "    seq_df['PHYC|Alpha Helical Propensity'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Aliphatic Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.aliphatic_index()\n",
    "    seq_df['PHYC|Aliphatic Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    # Calculating Boman Index\n",
    "    descrpt = GlobalDescriptor(seq_df['Sequence'].values)\n",
    "    descrpt.boman_index()\n",
    "    seq_df['PHYC|Boman Index'] = descrpt.descriptor.reshape(-1)\n",
    "\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert Amino acid composition to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., AAC_Ax ... AAC_Yx}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_aac(seq_df):\n",
    "    seq_df = seq_df.copy()\n",
    "    # Compute AAC for peptide in specific A.A\n",
    "    def get_aac(seq, aa):\n",
    "        # print(seq)\n",
    "        return seq.count(aa) / len(seq) * 100\n",
    "\n",
    "    # processing data_frame\n",
    "    data_size = seq_df.size\n",
    "    for ll in _AALetter:\n",
    "        seq_df['AAC|{}'.format(ll)] = list(map(get_aac, seq_df['Sequence'], [ll] * data_size))\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "'''\n",
    "Insert n_grams Descriptor to the sequence data_frame\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., ngram_(1), .., ngram(20 ** n)}\n",
    "'''\n",
    "\n",
    "\n",
    "def insert_ngrams(seq_df, n=2):\n",
    "    seq_df = seq_df.copy()\n",
    "    data_size = seq_df.size\n",
    "\n",
    "    ngrams_df = list(map(get_ngram_counts, seq_df['Sequence'], [n] * data_size))\n",
    "    ngrams_df = pd.DataFrame(ngrams_df)  # Convert ngrams features to pd.DataFrame\n",
    "    seq_df = pd.concat([seq_df, ngrams_df], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert CKSAAGP Descriptor to the sequence data_frame\n",
    "(Composition of k-spaced amino acid pairs)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_cksaagp(seq_df, gap=2):\n",
    "    seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = cksaagp(fastas, gap=gap)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert PAAC Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_paac(seq_df, lamb=3, w=0.1):\n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Insert Grouped n-gram Descriptor to the sequence data_frame\n",
    "(Pseudo Amino Acid Composition)\n",
    "Input: sequence data_frame {IDx: Seq_x, ...}\n",
    "Output: data_frame of Peptide Seq {IDx: Seq_x, ..., CKSAAGP(0), ..., CKSAAGP(m)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def insert_gngram(seq_df, n=1):\n",
    "    seq_df = seq_df.copy()\n",
    "    fastas = [[idx, seq] for idx, seq in zip(seq_df['Id'], seq_df['Sequence'])]\n",
    "    # encoding = paac(fastas, lambdaValue=lamb, w=w)\n",
    "    if n == 1:\n",
    "        encoding = GAAC(fastas)\n",
    "    elif n == 2:\n",
    "        encoding = GDPC(fastas)\n",
    "    elif n == 3:\n",
    "        encoding = GTPC(fastas)\n",
    "    else:\n",
    "        raise Warning(\"Invalid n-grams, no features added\")\n",
    "    encoding = pd.DataFrame(encoding[1:], columns=encoding[0])\n",
    "    seq_df = pd.concat([seq_df, encoding.iloc[:, 1:]], axis=1)\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "def construct_features(seq_df, paaclamb=4, paacw=0.5):\n",
    "    \"\"\"\n",
    "    Construct Features for the AVPIden. We first investigated physiochemical feautres, AAC features, DiC features,\n",
    "    CKSAAGP features, PAAC features, and PHYC features.\n",
    "    Parameters are pre-set accroding to the sequence identities.\n",
    "    \"\"\"\n",
    "    seq_df = insert_aac(seq_df)\n",
    "    seq_df = insert_ngrams(seq_df, n=2)\n",
    "    seq_df = insert_cksaagp(seq_df, gap=3) # As the maximum motif length = 5.\n",
    "    seq_df = insert_paac(seq_df, lamb=paaclamb, w=paacw)\n",
    "    seq_df = insert_phycs(seq_df)\n",
    "\n",
    "    return seq_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "nWfdwzyZ3f_o",
    "outputId": "05eddc73-04a3-46f4-d7b5-21a19ce30d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the entire-stage prediction data...\n",
      "Done!\n",
      "          Id                    Sequence      AAC|A      AAC|C     AAC|D  \\\n",
      "0        0_0             AWWRRTVAKVRKAMD  20.000000   0.000000  6.666667   \n",
      "1        1_1        FLPLLVGAISSILPKIFAMD  10.000000   0.000000  5.000000   \n",
      "2        2_0    GLNALKKVFQPIHEAIKLINNHVQ   8.333333   0.000000  0.000000   \n",
      "3        3_0            ILGKIWEGIESLFAMD   6.250000   0.000000  6.250000   \n",
      "4        4_0  GVTFNALKGVAKTVAAQLLKTARAMD  23.076923   0.000000  3.846154   \n",
      "...      ...                         ...        ...        ...       ...   \n",
      "1933  1933_1       KWKKLLKKLLPLLKKLLKKLK   0.000000   0.000000  0.000000   \n",
      "1934  1934_1          KIGAKIKIGAKIKIGAKI  16.666667   0.000000  0.000000   \n",
      "1935  1935_1                 DAACAAHCLWR  36.363636  18.181818  9.090909   \n",
      "1936  1936_0  RFDLVLVAARRARQMQSGGKDALVPE  15.384615   0.000000  7.692308   \n",
      "1937  1937_0                PVSLTSSLVFLM   0.000000   0.000000  0.000000   \n",
      "\n",
      "          AAC|E      AAC|F      AAC|G     AAC|H      AAC|I  ...  PAAC|lambda4  \\\n",
      "0      0.000000   0.000000   0.000000  0.000000   0.000000  ...      0.210914   \n",
      "1      0.000000  10.000000   5.000000  0.000000  15.000000  ...      0.134559   \n",
      "2      4.166667   4.166667   4.166667  8.333333  12.500000  ...      0.139857   \n",
      "3     12.500000   6.250000  12.500000  0.000000  18.750000  ...      0.185856   \n",
      "4      0.000000   3.846154   7.692308  0.000000   0.000000  ...      0.180707   \n",
      "...         ...        ...        ...       ...        ...  ...           ...   \n",
      "1933   0.000000   0.000000   0.000000  0.000000   0.000000  ...      0.126663   \n",
      "1934   0.000000   0.000000  16.666667  0.000000  33.333333  ...      0.117564   \n",
      "1935   0.000000   0.000000   0.000000  9.090909   0.000000  ...      0.221327   \n",
      "1936   3.846154   3.846154   7.692308  0.000000   0.000000  ...      0.250659   \n",
      "1937   0.000000   8.333333   0.000000  0.000000   0.000000  ...      0.155005   \n",
      "\n",
      "       PHYC|IEP  PHYC|Net Charge  PHYC|Hydrophobic Moment  \\\n",
      "0     11.723012         3.798148             5.425917e-01   \n",
      "1      6.086967        -0.236596             2.628972e-01   \n",
      "2      9.703282         1.934263             6.008901e-01   \n",
      "3      4.377705        -2.230975             3.708289e-01   \n",
      "4     10.289686         2.761396             3.339826e-01   \n",
      "...         ...              ...                      ...   \n",
      "1933  10.954420         9.750112             6.992261e-01   \n",
      "1934  10.699318         5.754108             1.018288e-16   \n",
      "1935   6.726520        -0.171415             4.683629e-01   \n",
      "1936  10.667342         1.769352             1.811967e-01   \n",
      "1937   5.954987        -0.041471             1.379471e-01   \n",
      "\n",
      "      PHYC|Hydrophobicity  PHYC|Transmembrane Propensity  PHYC|Aromacity  \\\n",
      "0                0.333333                      -0.646667        0.133333   \n",
      "1               -0.740000                       0.495500        0.100000   \n",
      "2               -0.220833                      -0.387500        0.041667   \n",
      "3               -0.275000                       0.087500        0.125000   \n",
      "4               -0.096154                      -0.212308        0.038462   \n",
      "...                   ...                            ...             ...   \n",
      "1933             0.495238                      -0.863333        0.047619   \n",
      "1934             0.316667                      -0.465000        0.000000   \n",
      "1935            -0.336364                      -0.273636        0.090909   \n",
      "1936             0.346154                      -0.556538        0.038462   \n",
      "1937            -0.975000                       0.700833        0.083333   \n",
      "\n",
      "      PHYC|Alpha Helical Propensity  PHYC|Aliphatic Index  PHYC|Boman Index  \n",
      "0                          1.089333             58.666667          3.108667  \n",
      "1                          1.036000            161.000000         -1.514000  \n",
      "2                          1.090417            130.000000          0.776667  \n",
      "3                          1.088750            128.125000         -0.291250  \n",
      "4                          1.090385            101.538462          0.585769  \n",
      "...                             ...                   ...               ...  \n",
      "1933                       1.214762            167.142857          0.423333  \n",
      "1934                       1.041667            146.666667         -0.248333  \n",
      "1935                       1.171818             71.818182          1.022727  \n",
      "1936                       1.073846             93.846154          2.408846  \n",
      "1937                       1.005000            145.833333         -1.283333  \n",
      "\n",
      "[1938 rows x 555 columns]         Id               Sequence      AAC|A  AAC|C     AAC|D     AAC|E  \\\n",
      "0      0_1          ALWKNMLKGIAMD  15.384615    0.0  7.692308  0.000000   \n",
      "1      1_1       FVPWFSKFLGRILAMD   6.250000    0.0  6.250000  0.000000   \n",
      "2      2_1       IKKIVSKIKKLLKAMD   6.250000    0.0  6.250000  0.000000   \n",
      "3      3_1       VRRFPWYWPFLRRAMD   6.250000    0.0  6.250000  0.000000   \n",
      "4      4_0      INLKAIAALAKKLLAMD  29.411765    0.0  5.882353  0.000000   \n",
      "..     ...                    ...        ...    ...       ...       ...   \n",
      "614  614_0         LTKTSRELDGIKVN   0.000000    0.0  7.142857  7.142857   \n",
      "615  615_0  LQRVLNVGLLLLAAILIVFLV   9.523810    0.0  0.000000  0.000000   \n",
      "616  616_1   FIGLLISAGKAIHDLIRRRH  10.000000    0.0  5.000000  0.000000   \n",
      "617  617_1            KKLFKKILKVL   0.000000    0.0  0.000000  0.000000   \n",
      "618  618_1       KWFKKIPKFLHLLKKF   0.000000    0.0  0.000000  0.000000   \n",
      "\n",
      "         AAC|F      AAC|G  AAC|H      AAC|I  ...  PAAC|lambda4   PHYC|IEP  \\\n",
      "0     0.000000   7.692308   0.00   7.692308  ...      0.128137   8.635234   \n",
      "1    18.750000   6.250000   0.00   6.250000  ...      0.106649   8.747925   \n",
      "2     0.000000   0.000000   0.00  18.750000  ...      0.152340  10.301548   \n",
      "3    12.500000   0.000000   0.00   0.000000  ...      0.180727  11.539019   \n",
      "4     0.000000   0.000000   0.00  11.764706  ...      0.216913   9.703024   \n",
      "..         ...        ...    ...        ...  ...           ...        ...   \n",
      "614   0.000000   7.142857   0.00   7.142857  ...      0.259155   8.589977   \n",
      "615   4.761905   4.761905   0.00   9.523810  ...      0.151894   9.750021   \n",
      "616   5.000000  10.000000  10.00  20.000000  ...      0.167539  11.711343   \n",
      "617   9.090909   0.000000   0.00   9.090909  ...      0.063389  10.602487   \n",
      "618  18.750000   0.000000   6.25   6.250000  ...      0.155800  10.699318   \n",
      "\n",
      "     PHYC|Net Charge  PHYC|Hydrophobic Moment  PHYC|Hydrophobicity  \\\n",
      "0           0.798178                 0.336609            -0.246154   \n",
      "1           0.763394                 0.407802            -0.643750   \n",
      "2           4.758409                 0.701992             0.562500   \n",
      "3           2.737251                 0.523950            -0.262500   \n",
      "4           1.761406                 0.219866            -0.141176   \n",
      "..               ...                      ...                  ...   \n",
      "614         0.762025                 0.323671             0.557143   \n",
      "615         0.760092                 0.249692            -1.147619   \n",
      "616         2.934542                 0.418301            -0.090000   \n",
      "617         4.755107                 0.846769             0.345455   \n",
      "618         5.841282                 0.663455            -0.037500   \n",
      "\n",
      "     PHYC|Transmembrane Propensity  PHYC|Aromacity  \\\n",
      "0                        -0.100000        0.076923   \n",
      "1                         0.303750        0.250000   \n",
      "2                        -0.735625        0.000000   \n",
      "3                        -0.241250        0.312500   \n",
      "4                        -0.044118        0.000000   \n",
      "..                             ...             ...   \n",
      "614                      -0.826429        0.000000   \n",
      "615                       0.993333        0.047619   \n",
      "616                      -0.107500        0.050000   \n",
      "617                      -0.584545        0.090909   \n",
      "618                      -0.546250        0.250000   \n",
      "\n",
      "     PHYC|Alpha Helical Propensity  PHYC|Aliphatic Index  PHYC|Boman Index  \n",
      "0                         1.156923            105.384615          0.008462  \n",
      "1                         1.035625             97.500000         -0.161250  \n",
      "2                         1.151250            146.250000          0.788750  \n",
      "3                         0.983125             48.750000          2.800000  \n",
      "4                         1.217059            167.058824         -0.524118  \n",
      "..                             ...                   ...               ...  \n",
      "614                       1.021429            104.285714          2.642143  \n",
      "615                       1.110476            250.476190         -2.180952  \n",
      "616                       1.048000            146.500000          1.441500  \n",
      "617                       1.181818            168.181818          0.095455  \n",
      "618                       1.136875             97.500000          0.438125  \n",
      "\n",
      "[619 rows x 555 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Entire\n",
    "    print(\"Translate the entire-stage prediction data...\", flush=True)\n",
    "    # if not os.path.exists(entire_datadir):\n",
    "    #     os.makedirs(entire_datadir)\n",
    "    df_train = read_fasta(\"train.fasta\")\n",
    "    df_train = construct_features(df_train)\n",
    "    df_test = read_fasta(\"test.fasta\")\n",
    "    df_test = construct_features(df_test)\n",
    "    print(\"Done!\", flush=True)\n",
    "    print(df_train, df_test)\n",
    "    # # ByFamily\n",
    "    # print(\"Translate the By-Family prediction data...\", flush=True)\n",
    "    # family_datadir = \"data/ByFamily/set\"\n",
    "    # if not os.path.exists(family_datadir):\n",
    "    #     os.makedirs(family_datadir)\n",
    "    # families = [\"Coronaviridae\", \"Flaviviridae\", \"Herpesviridae\",\n",
    "    # \"Orthomyxoviridae\", \"Paramyxoviridae\", \"Retroviridae\"]\n",
    "    # families = families + list(map(lambda x: \"non-\"+x, families))\n",
    "    # for fm in tqdm(families):\n",
    "    #     df = read_fasta(\"./Fasta/ByFamily/fasta/{:s}.faa\".format(fm))\n",
    "    #     df = construct_features(df)\n",
    "    #     df.to_csv(os.path.join(family_datadir, \"{:s}.csv\".format(fm)), index=False)\n",
    "    # print(\"Done!\", flush=True)\n",
    "    # # By virus\n",
    "    # print(\"Translate the By-Virus prediction data...\", flush=True)\n",
    "    # virus_datadir = \"data/ByVirus/set\"\n",
    "    # if not os.path.exists(virus_datadir):\n",
    "    #     os.makedirs(virus_datadir)\n",
    "    # viruses = [\"FIV\", \"HCV\", \"HIV\", \"HPIV3\", \"HSV1\", \"INFVA\",  \"RSV\", \"SARSCoV\"]\n",
    "    # viruses = viruses + list(map(lambda x: \"non-\"+x, viruses))\n",
    "    # for vm in tqdm(viruses):\n",
    "    #     df = read_fasta(\"./Fasta/ByVirus/fasta/{:s}.faa\".format(vm))\n",
    "    #     df = construct_features(df)\n",
    "    #     df.to_csv(os.path.join(virus_datadir, \"{:s}.csv\".format(vm)), index=False)\n",
    "    # print(\"Done!\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KuD9zQdQ0N5i",
    "outputId": "e9615640-f2e9-4a33-b3e7-470e1ea95131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the entire-stage prediction data in chunks...\n",
      "Processing last chunk with 1938 sequences.\n",
      "Done!\n",
      "Processed data saved to processed_features_train.csv\n",
      "Translate the entire-stage prediction data in chunks...\n",
      "Processing last chunk with 619 sequences.\n",
      "Done!\n",
      "Processed data saved to processed_features_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 逐行读取FASTA文件，生成数据\n",
    "def read_fasta_in_chunks(fasta_file, chunk_size=10000):\n",
    "    sequences = []\n",
    "    with open(fasta_file, 'r') as file:\n",
    "        sequence_id = None\n",
    "        sequence = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence_id is not None:\n",
    "                    sequences.append({\"Id\": sequence_id, \"Sequence\": ''.join(sequence)})\n",
    "                sequence_id = line[1:]  # 去掉 \">\" 符号\n",
    "                sequence = []\n",
    "            else:\n",
    "                sequence.append(line)\n",
    "            # 每处理 chunk_size 行数据，yield 一次\n",
    "            if len(sequences) >= chunk_size:\n",
    "                yield pd.DataFrame(sequences)\n",
    "                sequences = []\n",
    "        # 处理最后一批\n",
    "        if sequence_id is not None:\n",
    "            sequences.append({\"Id\": sequence_id, \"Sequence\": ''.join(sequence)})\n",
    "        if sequences:\n",
    "            # 打印最后一批的大小以确认没有问题\n",
    "            print(f\"Processing last chunk with {len(sequences)} sequences.\")\n",
    "            yield pd.DataFrame(sequences)\n",
    "\n",
    "\n",
    "# 假设 construct_features(df) 是定义好的特征构建函数\n",
    "def process_and_save_in_chunks(input_fasta, output_csv, chunk_size=10000):\n",
    "    processed_chunks = []\n",
    "    for chunk in read_fasta_in_chunks(input_fasta, chunk_size):\n",
    "        processed_chunk = construct_features(chunk)  # 调用特征构建函数\n",
    "        processed_chunks.append(processed_chunk)\n",
    "        # 可选：将每个chunk保存到文件（防止中途出错丢失结果）\n",
    "        processed_chunk.to_csv(output_csv, mode='a', index=False, header=not os.path.exists(output_csv))\n",
    "    return processed_chunks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Translate the entire-stage prediction data in chunks...\", flush=True)\n",
    "\n",
    "    input_fasta = \"train.fasta\"\n",
    "    output_csv = \"processed_features_train.csv\"\n",
    "\n",
    "    # 确保之前的输出文件不存在\n",
    "    if os.path.exists(output_csv):\n",
    "        os.remove(output_csv)\n",
    "\n",
    "    # 分批处理数据并保存到CSV\n",
    "    process_and_save_in_chunks(input_fasta, output_csv, chunk_size=10000)\n",
    "\n",
    "    print(\"Done!\", flush=True)\n",
    "    print(f\"Processed data saved to {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Translate the entire-stage prediction data in chunks...\", flush=True)\n",
    "\n",
    "    input_fasta = \"test.fasta\"\n",
    "    output_csv = \"processed_features_test.csv\"\n",
    "\n",
    "    # 确保之前的输出文件不存在\n",
    "    if os.path.exists(output_csv):\n",
    "        os.remove(output_csv)\n",
    "\n",
    "    # 分批处理数据并保存到CSV\n",
    "    process_and_save_in_chunks(input_fasta, output_csv, chunk_size=10000)\n",
    "\n",
    "    print(\"Done!\", flush=True)\n",
    "    print(f\"Processed data saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDKRbqs9Drrw"
   },
   "outputs": [],
   "source": [
    "# Save the processed data to CSV files\n",
    "df_train.to_csv('train_feature.csv',index=False)\n",
    "df_test.to_csv('test_feature.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AXIS",
   "language": "python",
   "name": "axis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
